{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 初始化配置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Config(object):\r\n",
    "    def __init__(self):\r\n",
    "        self.dataPath = '.'\r\n",
    "        self.trainRatio = '0.8'\r\n",
    "        self.modelPath = './model/wz.pdparams'\r\n",
    "        self.logPath = './logs'\r\n",
    "        self.pointsPath = 'checkpoint'\r\n",
    "        self.inferencePath = './inference/wz'\r\n",
    "        self.use_gpu = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddle.nn import Linear\r\n",
    "import paddle.nn.functional as F\r\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "class WZPredict(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(WZPredict, self).__init__()\r\n",
    "         \r\n",
    "        self.fc1 = paddle.nn.Linear(in_features=29, out_features=60)\r\n",
    "        self.fc2 = paddle.nn.Linear(in_features=60, out_features=40)\r\n",
    "        self.fc3 = paddle.nn.Linear(in_features=40, out_features=20)\r\n",
    "        self.fc4 = paddle.nn.Linear(in_features=20, out_features=10)\r\n",
    "        self.fc5 = paddle.nn.Linear(in_features=10, out_features=6)\r\n",
    "        self.fc6 = paddle.nn.Linear(in_features=6, out_features=2)\r\n",
    "        self.relu = paddle.nn.ReLU()\r\n",
    "    \r\n",
    "    @paddle.jit.to_static  # 添加装饰器，使动态图网络结构在静态图模式下运行\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = self.fc1(inputs)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc2(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc3(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc4(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc5(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc6(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "class DataAsync(paddle.io.Dataset):\r\n",
    "    def __init__(self, mode='train'):\r\n",
    "        \r\n",
    "        cf = Config()\r\n",
    "        self.cf = cf\r\n",
    "        self.dataPath = cf.dataPath\r\n",
    "        self.trainRatio = float(cf.trainRatio)\r\n",
    "        self.datas = []\r\n",
    "        self.labels = []\r\n",
    "        self.mean = []\r\n",
    "        self.std = []\r\n",
    "        \r\n",
    "        train_df = pd.read_csv(self.dataPath+'/train.csv')\r\n",
    "        labels = np.array(train_df['win']).astype('int64')\r\n",
    "        train_df = train_df.drop(['id', 'timecc','win'], axis=1)\r\n",
    "        datas = np.array(train_df.values.tolist())\r\n",
    "        \r\n",
    "        self.mean = np.mean(datas,axis = 0)\r\n",
    "        self.std = np.std(datas,axis = 0)\r\n",
    "    \r\n",
    "        \r\n",
    "        offset = int(datas.shape[0] * self.trainRatio)\r\n",
    "        print(datas.shape[0], self.trainRatio, offset)\r\n",
    "        self.labels = labels[:offset] if mode == 'train' else labels[offset:]\r\n",
    "        self.datas = datas[:offset] if mode == 'train' else datas[offset:]\r\n",
    "\r\n",
    "        print(self.labels.shape)\r\n",
    "        print(self.datas.shape)\r\n",
    "        \r\n",
    "        \r\n",
    "    def __getitem__(self, idx):\r\n",
    "        data = (self.datas[idx] - self.mean)/self.std\r\n",
    "        label = self.labels[idx]\r\n",
    "\r\n",
    "\r\n",
    "        data = np.reshape(data, [29]).astype('float32')\r\n",
    "        label = np.reshape(label, [1]).astype('int64')\r\n",
    "        return data, label\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddle.nn import Linear\r\n",
    "import paddle.nn.functional as F\r\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "class WZPredict(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(WZPredict, self).__init__()\r\n",
    "         \r\n",
    "        self.fc1 = paddle.nn.Linear(in_features=29, out_features=60)\r\n",
    "        self.fc2 = paddle.nn.Linear(in_features=60, out_features=40)\r\n",
    "        self.fc3 = paddle.nn.Linear(in_features=40, out_features=20)\r\n",
    "        self.fc4 = paddle.nn.Linear(in_features=20, out_features=10)\r\n",
    "        self.fc5 = paddle.nn.Linear(in_features=10, out_features=6)\r\n",
    "        self.fc6 = paddle.nn.Linear(in_features=6, out_features=2)\r\n",
    "        self.relu = paddle.nn.ReLU()\r\n",
    "    \r\n",
    "    @paddle.jit.to_static  # 添加装饰器，使动态图网络结构在静态图模式下运行\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = self.fc1(inputs)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc2(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc3(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc4(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc5(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.fc6(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000 0.8 144000\n",
      "(144000,)\n",
      "(144000, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [0.69031024], acc is [0.5164286]\n",
      "epoch: 0, batch: 100, loss is: [0.49212542], acc is [0.825]\n",
      "epoch: 1, batch: 0, loss is: [0.48253977], acc is [0.8207143]\n",
      "epoch: 1, batch: 100, loss is: [0.3623078], acc is [0.82857144]\n",
      "epoch: 2, batch: 0, loss is: [0.36389598], acc is [0.83]\n",
      "epoch: 2, batch: 100, loss is: [0.36219525], acc is [0.8192857]\n",
      "epoch: 3, batch: 0, loss is: [0.32167023], acc is [0.85714287]\n",
      "epoch: 3, batch: 100, loss is: [0.3407231], acc is [0.8521429]\n",
      "epoch: 4, batch: 0, loss is: [0.34469593], acc is [0.84]\n",
      "epoch: 4, batch: 100, loss is: [0.32857063], acc is [0.8442857]\n",
      "epoch: 5, batch: 0, loss is: [0.35593274], acc is [0.8257143]\n",
      "epoch: 5, batch: 100, loss is: [0.33116665], acc is [0.85642856]\n",
      "epoch: 6, batch: 0, loss is: [0.3564794], acc is [0.83928573]\n",
      "epoch: 6, batch: 100, loss is: [0.34613478], acc is [0.83214283]\n",
      "epoch: 7, batch: 0, loss is: [0.35950345], acc is [0.82357144]\n",
      "epoch: 7, batch: 100, loss is: [0.35375994], acc is [0.83357143]\n",
      "epoch: 8, batch: 0, loss is: [0.3523275], acc is [0.82857144]\n",
      "epoch: 8, batch: 100, loss is: [0.3333862], acc is [0.8428571]\n",
      "epoch: 9, batch: 0, loss is: [0.35139784], acc is [0.8264286]\n",
      "epoch: 9, batch: 100, loss is: [0.33590105], acc is [0.8542857]\n",
      "epoch: 10, batch: 0, loss is: [0.31137437], acc is [0.85142857]\n",
      "epoch: 10, batch: 100, loss is: [0.321862], acc is [0.8492857]\n",
      "epoch: 11, batch: 0, loss is: [0.35573328], acc is [0.835]\n",
      "epoch: 11, batch: 100, loss is: [0.36272657], acc is [0.8364286]\n",
      "epoch: 12, batch: 0, loss is: [0.33914936], acc is [0.85071427]\n",
      "epoch: 12, batch: 100, loss is: [0.31454444], acc is [0.855]\n",
      "epoch: 13, batch: 0, loss is: [0.34090802], acc is [0.8414286]\n",
      "epoch: 13, batch: 100, loss is: [0.33031476], acc is [0.85071427]\n",
      "epoch: 14, batch: 0, loss is: [0.33224902], acc is [0.8492857]\n",
      "epoch: 14, batch: 100, loss is: [0.3505699], acc is [0.83]\n",
      "epoch: 15, batch: 0, loss is: [0.33503282], acc is [0.8385714]\n",
      "epoch: 15, batch: 100, loss is: [0.32515314], acc is [0.85714287]\n",
      "epoch: 16, batch: 0, loss is: [0.34551385], acc is [0.8385714]\n",
      "epoch: 16, batch: 100, loss is: [0.32434884], acc is [0.85]\n",
      "epoch: 17, batch: 0, loss is: [0.32124138], acc is [0.8521429]\n",
      "epoch: 17, batch: 100, loss is: [0.3415943], acc is [0.8357143]\n",
      "epoch: 18, batch: 0, loss is: [0.31861112], acc is [0.85714287]\n",
      "epoch: 18, batch: 100, loss is: [0.31903875], acc is [0.8535714]\n",
      "epoch: 19, batch: 0, loss is: [0.30934864], acc is [0.85071427]\n",
      "epoch: 19, batch: 100, loss is: [0.33307934], acc is [0.8307143]\n",
      "epoch: 20, batch: 0, loss is: [0.31662163], acc is [0.8471429]\n",
      "epoch: 20, batch: 100, loss is: [0.33126518], acc is [0.8542857]\n",
      "epoch: 21, batch: 0, loss is: [0.34396097], acc is [0.8442857]\n",
      "epoch: 21, batch: 100, loss is: [0.32170755], acc is [0.85571426]\n",
      "epoch: 22, batch: 0, loss is: [0.32045043], acc is [0.85]\n",
      "epoch: 22, batch: 100, loss is: [0.31136003], acc is [0.8528572]\n",
      "epoch: 23, batch: 0, loss is: [0.30881914], acc is [0.86214286]\n",
      "epoch: 23, batch: 100, loss is: [0.32254303], acc is [0.8521429]\n",
      "epoch: 24, batch: 0, loss is: [0.31903547], acc is [0.85071427]\n",
      "epoch: 24, batch: 100, loss is: [0.33257374], acc is [0.8435714]\n",
      "epoch: 25, batch: 0, loss is: [0.3682074], acc is [0.8207143]\n",
      "epoch: 25, batch: 100, loss is: [0.32810345], acc is [0.8471429]\n",
      "epoch: 26, batch: 0, loss is: [0.32083166], acc is [0.85571426]\n",
      "epoch: 26, batch: 100, loss is: [0.31768194], acc is [0.85]\n",
      "epoch: 27, batch: 0, loss is: [0.3430513], acc is [0.8414286]\n",
      "epoch: 27, batch: 100, loss is: [0.3266591], acc is [0.84]\n",
      "epoch: 28, batch: 0, loss is: [0.34956396], acc is [0.83214283]\n",
      "epoch: 28, batch: 100, loss is: [0.3229984], acc is [0.8464286]\n",
      "epoch: 29, batch: 0, loss is: [0.3485485], acc is [0.8264286]\n",
      "epoch: 29, batch: 100, loss is: [0.33945534], acc is [0.8492857]\n",
      "epoch: 30, batch: 0, loss is: [0.32780913], acc is [0.8485714]\n",
      "epoch: 30, batch: 100, loss is: [0.33121648], acc is [0.85571426]\n",
      "epoch: 31, batch: 0, loss is: [0.34017503], acc is [0.8407143]\n",
      "epoch: 31, batch: 100, loss is: [0.3158352], acc is [0.8592857]\n",
      "epoch: 32, batch: 0, loss is: [0.3167891], acc is [0.8635714]\n",
      "epoch: 32, batch: 100, loss is: [0.330242], acc is [0.8478571]\n",
      "epoch: 33, batch: 0, loss is: [0.3238664], acc is [0.8435714]\n",
      "epoch: 33, batch: 100, loss is: [0.30473182], acc is [0.86642855]\n",
      "epoch: 34, batch: 0, loss is: [0.3260058], acc is [0.8535714]\n",
      "epoch: 34, batch: 100, loss is: [0.3083184], acc is [0.855]\n",
      "epoch: 35, batch: 0, loss is: [0.3289551], acc is [0.845]\n",
      "epoch: 35, batch: 100, loss is: [0.3264937], acc is [0.8371429]\n",
      "epoch: 36, batch: 0, loss is: [0.33210132], acc is [0.86071426]\n",
      "epoch: 36, batch: 100, loss is: [0.33392265], acc is [0.8378571]\n",
      "epoch: 37, batch: 0, loss is: [0.29956546], acc is [0.85071427]\n",
      "epoch: 37, batch: 100, loss is: [0.33603176], acc is [0.8528572]\n",
      "epoch: 38, batch: 0, loss is: [0.30953464], acc is [0.86071426]\n",
      "epoch: 38, batch: 100, loss is: [0.3023832], acc is [0.8642857]\n",
      "epoch: 39, batch: 0, loss is: [0.32057914], acc is [0.85]\n",
      "epoch: 39, batch: 100, loss is: [0.3174656], acc is [0.8471429]\n",
      "epoch: 40, batch: 0, loss is: [0.30974284], acc is [0.8635714]\n",
      "epoch: 40, batch: 100, loss is: [0.32722625], acc is [0.8464286]\n",
      "epoch: 41, batch: 0, loss is: [0.31637627], acc is [0.8471429]\n",
      "epoch: 41, batch: 100, loss is: [0.30728], acc is [0.86785716]\n",
      "epoch: 42, batch: 0, loss is: [0.30668008], acc is [0.86285716]\n",
      "epoch: 42, batch: 100, loss is: [0.3171801], acc is [0.86]\n",
      "epoch: 43, batch: 0, loss is: [0.3305791], acc is [0.835]\n",
      "epoch: 43, batch: 100, loss is: [0.30773574], acc is [0.86071426]\n",
      "epoch: 44, batch: 0, loss is: [0.3279782], acc is [0.8521429]\n",
      "epoch: 44, batch: 100, loss is: [0.32802904], acc is [0.85142857]\n",
      "epoch: 45, batch: 0, loss is: [0.27968392], acc is [0.87214285]\n",
      "epoch: 45, batch: 100, loss is: [0.31241718], acc is [0.85785717]\n",
      "epoch: 46, batch: 0, loss is: [0.33323702], acc is [0.8385714]\n",
      "epoch: 46, batch: 100, loss is: [0.3137558], acc is [0.865]\n",
      "epoch: 47, batch: 0, loss is: [0.32050657], acc is [0.8478571]\n",
      "epoch: 47, batch: 100, loss is: [0.31499276], acc is [0.86642855]\n",
      "epoch: 48, batch: 0, loss is: [0.32298276], acc is [0.8428571]\n",
      "epoch: 48, batch: 100, loss is: [0.30830288], acc is [0.8585714]\n",
      "epoch: 49, batch: 0, loss is: [0.3092178], acc is [0.87]\n",
      "epoch: 49, batch: 100, loss is: [0.32428005], acc is [0.8471429]\n"
     ]
    }
   ],
   "source": [
    "from operator import mod\r\n",
    "import paddle\r\n",
    "from paddle.nn import Linear\r\n",
    "import paddle.nn.functional as F\r\n",
    "from visualdl import LogWriter\r\n",
    "import numpy as np\r\n",
    "class Train(object):\r\n",
    "    batch_size = 1400\r\n",
    "    EPOCH_NUM = 50\r\n",
    "    data = None\r\n",
    "    def __init__(self):\r\n",
    "        cf = Config()\r\n",
    "        self.log_writer = LogWriter(cf.logPath)\r\n",
    "        self.modelPath = cf.modelPath\r\n",
    "        self.logPath = cf.logPath\r\n",
    "        self.pointsPath = cf.pointsPath\r\n",
    "        self.use_gpu = cf.use_gpu\r\n",
    "        \r\n",
    "    def run(self, startStp = 0):\r\n",
    "        model = WZPredict()\r\n",
    "        #开启GPU\r\n",
    "        paddle.set_device('gpu:0') if self.use_gpu else paddle.set_device('cpu')\r\n",
    "\r\n",
    "        train_dataset = DataAsync(mode='train')\r\n",
    "        train_loader = paddle.io.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=0, drop_last=True, use_shared_memory=False)\r\n",
    "\r\n",
    "        #各种优化算法均可以加入正则化项，避免过拟合，参数regularization_coeff调节正则化项的权重\r\n",
    "        opt = paddle.optimizer.Adam(learning_rate=0.0008, weight_decay=paddle.regularizer.L2Decay(coeff=1e-5), parameters=model.parameters())\r\n",
    "        if startStp > 0:\r\n",
    "            params_dict = paddle.load('./{}/wz_epoch{}'.format(self.pointsPath,startStp-1)+'.pdparams')\r\n",
    "            opt_dict = paddle.load('./{}/wz_epoch{}'.format(self.pointsPath,startStp-1)+'.pdopt')\r\n",
    "\r\n",
    "            # 加载参数到模型\r\n",
    "            model.set_state_dict(params_dict)\r\n",
    "            opt.set_state_dict(opt_dict)\r\n",
    "        \r\n",
    "        iter = 0\r\n",
    "        for epoch_id in range(startStp, self.EPOCH_NUM):\r\n",
    "            for batch_id, data in enumerate(train_loader()):\r\n",
    "                #准备数据，变得更加简洁\r\n",
    "                datas, labels = data\r\n",
    "                datas = paddle.to_tensor(datas)\r\n",
    "                labels = paddle.to_tensor(labels)\r\n",
    "\r\n",
    "                \r\n",
    "                #前向计算的过程\r\n",
    "                predits = model(datas)\r\n",
    "                acc = paddle.metric.accuracy(input=predits, label=labels)\r\n",
    "                loss = F.cross_entropy(predits, labels)\r\n",
    "                avg_loss = paddle.mean(loss)    \r\n",
    "                \r\n",
    "                #每训练了200批次的数据，打印下当前Loss的情况\r\n",
    "                if batch_id % 100 == 0:\r\n",
    "                    print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\r\n",
    "                    self.log_writer.add_scalar(tag = 'acc', step = iter, value = acc.numpy())\r\n",
    "                    self.log_writer.add_scalar(tag = 'loss', step = iter, value = avg_loss.numpy())\r\n",
    "                    iter = iter + 100\r\n",
    "                #后向传播，更新参数的过程\r\n",
    "                avg_loss.backward()\r\n",
    "                opt.step()\r\n",
    "                opt.clear_grad()\r\n",
    "            \r\n",
    "            # 每个批次保存一次\r\n",
    "            paddle.save(opt.state_dict(), './{}/wz_epoch{}'.format(self.pointsPath,epoch_id)+'.pdopt')\r\n",
    "            paddle.save(model.state_dict(), './{}/wz_epoch{}'.format(self.pointsPath,epoch_id)+'.pdparams')\r\n",
    "\r\n",
    "        # 保存模型\r\n",
    "        paddle.save(model.state_dict(), self.modelPath)\r\n",
    "        \r\n",
    "train = Train()\r\n",
    "train.run()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000 0.8 144000\n",
      "(36000,)\n",
      "(36000, 29)\n",
      "batch: 0, loss is: [0.54243577], acc is [0.7]\n",
      "batch: 100, loss is: [0.55123055], acc is [0.7]\n",
      "batch: 200, loss is: [0.44265738], acc is [0.8]\n",
      "batch: 300, loss is: [0.38558355], acc is [0.8]\n",
      "batch: 400, loss is: [0.39668372], acc is [0.8]\n",
      "batch: 500, loss is: [0.5111179], acc is [0.8]\n",
      "batch: 600, loss is: [0.46419412], acc is [0.8]\n",
      "batch: 700, loss is: [0.8092197], acc is [0.6]\n",
      "batch: 800, loss is: [0.2705981], acc is [0.9]\n",
      "batch: 900, loss is: [0.18662393], acc is [0.8]\n",
      "batch: 1000, loss is: [0.5244156], acc is [0.7]\n",
      "batch: 1100, loss is: [0.5667521], acc is [0.8]\n",
      "batch: 1200, loss is: [0.36851034], acc is [0.7]\n",
      "batch: 1300, loss is: [0.1477359], acc is [0.9]\n",
      "batch: 1400, loss is: [0.81704557], acc is [0.4]\n",
      "batch: 1500, loss is: [0.22093725], acc is [0.9]\n",
      "batch: 1600, loss is: [0.26100057], acc is [0.9]\n",
      "batch: 1700, loss is: [0.5651214], acc is [0.8]\n",
      "batch: 1800, loss is: [0.3174451], acc is [0.8]\n",
      "batch: 1900, loss is: [0.26437032], acc is [0.9]\n",
      "batch: 2000, loss is: [0.3615585], acc is [0.8]\n",
      "batch: 2100, loss is: [0.29710793], acc is [0.9]\n",
      "batch: 2200, loss is: [0.33933982], acc is [0.7]\n",
      "batch: 2300, loss is: [0.50316983], acc is [0.8]\n",
      "batch: 2400, loss is: [0.51752996], acc is [0.7]\n",
      "batch: 2500, loss is: [0.48954648], acc is [0.8]\n",
      "batch: 2600, loss is: [0.10496423], acc is [1.]\n",
      "batch: 2700, loss is: [0.43012196], acc is [0.7]\n",
      "batch: 2800, loss is: [0.14887793], acc is [0.9]\n",
      "batch: 2900, loss is: [0.64328265], acc is [0.7]\n",
      "batch: 3000, loss is: [0.24265137], acc is [0.9]\n",
      "batch: 3100, loss is: [0.29111528], acc is [0.9]\n",
      "batch: 3200, loss is: [0.05471524], acc is [1.]\n",
      "batch: 3300, loss is: [0.33563122], acc is [0.8]\n",
      "batch: 3400, loss is: [0.18689325], acc is [0.9]\n",
      "batch: 3500, loss is: [0.18574473], acc is [1.]\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "from visualdl import LogWriter\r\n",
    "class Eval(object):\r\n",
    "    batch_size = 10\r\n",
    "    EPOCH_NUM = 10\r\n",
    "    data = None\r\n",
    "    def __init__(self):\r\n",
    "        cf = Config()\r\n",
    "        self.log_writer = LogWriter(cf.logPath)\r\n",
    "        self.modelPath = cf.modelPath\r\n",
    "        self.logPath = cf.logPath\r\n",
    "        self.pointsPath = cf.pointsPath\r\n",
    "        self.use_gpu = cf.use_gpu\r\n",
    "        \r\n",
    "    def run(self):\r\n",
    "        model = WZPredict()\r\n",
    "        #开启GPU\r\n",
    "        paddle.set_device('gpu:0') if self.use_gpu else paddle.set_device('cpu')\r\n",
    "\r\n",
    "        valid_dataset = DataAsync(mode='vaild')\r\n",
    "        valid_loader = paddle.io.DataLoader(valid_dataset, batch_size=self.batch_size, shuffle=False, num_workers=0, drop_last=False, use_shared_memory=False)\r\n",
    "       \r\n",
    "        # 加载模型参数\r\n",
    "        param_dict = paddle.load(self.modelPath)\r\n",
    "        model.load_dict(param_dict)\r\n",
    "        model.eval()\r\n",
    "        for vaild_id, vaild_data in enumerate(valid_loader()):\r\n",
    "            datas_v, labels_v = vaild_data\r\n",
    "            datas_v = paddle.to_tensor(datas_v)\r\n",
    "            labels_v = paddle.to_tensor(labels_v)\r\n",
    "            predits_v = model(datas_v)\r\n",
    "            acc_v = paddle.metric.accuracy(input=predits_v, label=labels_v)\r\n",
    "            loss_v = F.cross_entropy(predits_v, labels_v)\r\n",
    "            avg_loss_v = paddle.mean(loss_v)\r\n",
    "            if vaild_id % 100 == 0:\r\n",
    "                print(\"batch: {}, loss is: {}, acc is {}\".format(vaild_id, avg_loss_v.numpy(), acc_v.numpy()))\r\n",
    "        \r\n",
    "eval = Eval()\r\n",
    "eval.run()\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 导出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Inference model saved in  ./inference/wz\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "from paddle.static import InputSpec\r\n",
    "\r\n",
    "class Save(object):\r\n",
    "    def __init__(self):\r\n",
    "        cf = Config()\r\n",
    "        self.dataPath = cf.dataPath\r\n",
    "        self.modelPath = cf.modelPath\r\n",
    "        self.inferencePath = cf.inferencePath\r\n",
    "        self.pointsPath = cf.pointsPath\r\n",
    "        self.use_gpu = cf.use_gpu\r\n",
    "        \r\n",
    "    def run(self):\r\n",
    "        model = WZPredict()\r\n",
    "    \r\n",
    "        # 加载模型参数\r\n",
    "        param_dict = paddle.load(self.modelPath)\r\n",
    "        model.load_dict(param_dict)\r\n",
    "        model.eval()\r\n",
    "        \r\n",
    "        # 保存inference模型\r\n",
    "        paddle.jit.save(\r\n",
    "        layer=model,\r\n",
    "        path=self.inferencePath,\r\n",
    "        input_spec=[InputSpec(shape=[None, 29], dtype='float32')])\r\n",
    "\r\n",
    "        # input_spec 是根据模型 forward 参数的接入shape,多个参数接入目前不知道如何写\r\n",
    "        print(\"==>Inference model saved in \", self.inferencePath)\r\n",
    "        \r\n",
    "save = Save()\r\n",
    "save.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 生成预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20001\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "import paddle\r\n",
    "import os\r\n",
    "import csv\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "class Predict(object):\r\n",
    "    data = None\r\n",
    "    def __init__(self):\r\n",
    "        cf = Config()\r\n",
    "        self.dataPath = cf.dataPath\r\n",
    "        self.modelPath = cf.modelPath\r\n",
    "        self.logPath = cf.logPath\r\n",
    "        self.pointsPath = cf.pointsPath\r\n",
    "        self.use_gpu = cf.use_gpu\r\n",
    "        self.inferencePath = cf.inferencePath\r\n",
    "\r\n",
    "        \r\n",
    "    def run(self):\r\n",
    "\r\n",
    "        loaded_model = paddle.jit.load(self.inferencePath)\r\n",
    "        paddle.set_device('gpu:0') if self.use_gpu else paddle.set_device('cpu')\r\n",
    "       \r\n",
    "        train_df = pd.read_csv(self.dataPath+'/train.csv')\r\n",
    "        train_df = train_df.drop(['id', 'timecc','win'], axis=1)\r\n",
    "        datas = np.array(train_df.values.tolist())\r\n",
    "        mean = np.mean(datas,axis = 0)\r\n",
    "        std = np.std(datas,axis = 0)\r\n",
    "\r\n",
    "\r\n",
    "        test_df = pd.read_csv(self.dataPath+'/test.csv')\r\n",
    "        test_df = test_df.drop(['id', 'timecc'], axis=1)\r\n",
    "        datas = np.array(test_df.values.tolist())\r\n",
    "\r\n",
    "        results = [['win']]\r\n",
    "\r\n",
    "        for data in datas:\r\n",
    "            data = (data - mean)/std\r\n",
    "            data = np.reshape(data, [1,29]).astype('float32')\r\n",
    "            data = paddle.to_tensor(data)\r\n",
    "            label = loaded_model(data)\r\n",
    "            label = paddle.argmax(label)\r\n",
    "            results.append([int(label)])\r\n",
    "        \r\n",
    "        print(len(results))\r\n",
    "\r\n",
    "        with open(self.dataPath + \"/submission.csv\", \"w\", newline='') as csvfile:\r\n",
    "            writer = csv.writer(csvfile)\r\n",
    "            writer.writerows(results)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "predict = Predict()\r\n",
    "predict.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: submission.csv (deflated 93%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip submission.zip submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
